# OpenAI Chat Agent Environment Variables
# Copy this file to .env and fill in your values

# OpenAI Configuration
# Get your API key from: https://platform.openai.com/api-keys
# If set, the agent will use OpenAI's GPT-4o model
# If not set, the agent will fall back to local Ollama
# OPENAI_API_KEY=sk-...

# Ollama Configuration
# Only used if OPENAI_API_KEY is not set
# Default model to use with local Ollama server
# Popular options: llama3.2, llama3.1, llama3, codellama, mistral, phi3
# Make sure to pull the model first: ollama pull llama3.2
# OLLAMA_MODEL=llama3.2

# Ollama Server Configuration (optional)
# Uncomment and modify if your Ollama server is not running on default settings
# OLLAMA_HOST=http://localhost:11434
# OLLAMA_MODELS=/path/to/your/models

# Logging Configuration (optional)
# Set to DEBUG for more verbose output
# LOG_LEVEL=INFO
